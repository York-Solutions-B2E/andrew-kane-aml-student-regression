{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Grades Regression Analysis\n",
    "### Process Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ETL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Addressed raw data handling and database-related requests before any data interpretation or manipulation\n",
    "    * Rationale: If client wants ability to update dataset, they would doubtless intend for predictive model to be used on the most up-to-date version of the data\n",
    "* Establishing database was done with SQLAlchemy\n",
    "* Other functions done with psycopg2\n",
    "* Ideally would be able to do all functions with one library but moved on for the sake of time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Examined schema in detail to isolate nominal, ordinal, numeric features\n",
    "* Studied categorical features and decided to encode at this point to facilitate analysis / visualization\n",
    "* Chose encoding options to address large number of categorical features while minimizing dimensionality increase\n",
    "* Looked at: \n",
    "    * Overall feature distribution\n",
    "    * All possible correlations\n",
    "    * Relation of most correlated features\n",
    "    * Mutual information scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Decided to attempt testing different feature sets alongside / concurrently with different estimators to make process more robust against missing out on good combinations\n",
    "\n",
    "* Used insights from examining the dataset to come up with candidate feature sets\n",
    "* Tried:\n",
    "    * Isolating features with most mutual information\n",
    "    * Dropping features with no mutual information\n",
    "    * Dropping features with least variance\n",
    "    * Including engineered 'mean grades' feature\n",
    "    * Recursive feature elimination\n",
    "    * KBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wrote validation function to test set of sets against all candidate estimators\n",
    "    * Performed two rounds of candidate estimator validation\n",
    "    * Chose suite of estimators based on scikit-learn's algorithm selection flowchart\n",
    "    * Round 1: SVR (linear), SVR (rbf), Lasso, ElasticNet, Ridge, Random Forest (winner)\n",
    "    * Round 2: Random Forest, Linear Regression, Gradient Boost, Voting Regression\n",
    "    * Random Forest performed best across all metrics\n",
    "* Hyperparameter tuning: chose the randomized search algorithm as its use is indicated when the model has many hyperparameters and one lacks knowledge about which ones are important\n",
    "* Minimal effect on validation performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Metric selection: Mean absolute error, R^2, root mean squared error\n",
    "* Attempted to go with metrics that are commonly used in regression problems and are easy to interpret\n",
    "* Paired MAE with RMSE to have two takes in the same units on the significance of outliers (found in e.g. 'absences', a feature included in many of the candidate sets)\n",
    "* Included R^2 as most independent variables were pared down in feature selection and the most important features had a somewhat linear relationship with the target"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
